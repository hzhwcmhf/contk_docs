

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Resources &mdash; cotk  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/cotk_theme.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="file_utils" href="file_utils.html" />
    <link rel="prev" title="Metric" href="metric.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> cotk
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notes/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/quickstart.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/tutorial_core.html">Practice: Implement a GRU Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/cli_usage.html">CLI Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/extend.html">Extending Cotk: More Data, More Metrics!</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/FAQ.html">Frequently Asked Questions</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="dataloader.html">Data Loader</a></li>
<li class="toctree-l1"><a class="reference internal" href="wordvector.html">Word Vector</a></li>
<li class="toctree-l1"><a class="reference internal" href="metric.html">Metric</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Resources</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#file-id">File ID</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#download-import-resources-manually">Download / Import Resources Manually</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#word-vector">Word Vector</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#glove50d">Glove50d</a></li>
<li class="toctree-l3"><a class="reference internal" href="#glove100d">Glove100d</a></li>
<li class="toctree-l3"><a class="reference internal" href="#glove200d">Glove200d</a></li>
<li class="toctree-l3"><a class="reference internal" href="#glove300d">Glove300d</a></li>
<li class="toctree-l3"><a class="reference internal" href="#glove50d-small">Glove50d_small</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#datasets">Datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#mscoco">MSCOCO</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mscoco-small">MSCOCO_small</a></li>
<li class="toctree-l3"><a class="reference internal" href="#opensubtitles">OpenSubtitles</a></li>
<li class="toctree-l3"><a class="reference internal" href="#opensubtitles-small">OpenSubtitles_small</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sst">SST</a></li>
<li class="toctree-l3"><a class="reference internal" href="#switchboardcorpus">SwitchboardCorpus</a></li>
<li class="toctree-l3"><a class="reference internal" href="#switchboardcorpus-small">SwitchboardCorpus_small</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ubuntu">Ubuntu</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ubuntu-small">Ubuntu_small</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="file_utils.html">file_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="file_utils.html#resources-processor">resources_processor</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Zoo</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="models/LanguageGeneration/index.html">LanguageGeneration</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/SingleTurnDialog/index.html">SingleTurnDialog</a></li>
<li class="toctree-l1"><a class="reference internal" href="models/MultiTurnDialog/index.html">MultiTurnDialog</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">cotk</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Resources</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/resources.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="resources">
<span id="resources-reference"></span><h1>Resources<a class="headerlink" href="#resources" title="Permalink to this headline">¶</a></h1>
<div class="section" id="file-id">
<span id="id1"></span><h2>File ID<a class="headerlink" href="#file-id" title="Permalink to this headline">¶</a></h2>
<p>Classes like <code class="xref py py-class docutils literal notranslate"><span class="pre">dataloder.Dataloader</span></code> usually need <code class="docutils literal notranslate"><span class="pre">file_id</span></code> to locate
resources. The string will be passed to <code class="xref py py-meth docutils literal notranslate"><span class="pre">file_utils.file_utils.get_resource_file_path()</span></code> or
<code class="xref py py-meth docutils literal notranslate"><span class="pre">file_utils.file_utils.import_local_resources()</span></code>.</p>
<p>The format  of <code class="docutils literal notranslate"><span class="pre">file_id</span></code> is <code class="docutils literal notranslate"><span class="pre">name[&#64;source][#processor]</span></code>,
where <code class="docutils literal notranslate"><span class="pre">source</span></code> and <code class="docutils literal notranslate"><span class="pre">processor</span></code> are optional.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code> can be:</p>
<blockquote>
<div><ul class="simple">
<li><p>A string start with “resources://”, indicating predefined resources.</p></li>
<li><p>A string start with “<a class="reference external" href="https://">https://</a>” indicating online resources.</p></li>
<li><p>A string indicating local path, absolute or relative to cwd.</p></li>
</ul>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">source</span></code> only works when <code class="docutils literal notranslate"><span class="pre">name</span></code> indicates a predefined resources,
where <code class="docutils literal notranslate"><span class="pre">source</span></code> means where to download the dataset.
See the following sections of a specific resource for all availiable <code class="docutils literal notranslate"><span class="pre">source</span></code>.
If not specified, a default source will be chosen
(the first one in the list showing source).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">preprocessor</span></code> is necessary when <code class="docutils literal notranslate"><span class="pre">name</span></code> is not a predefined resources.
It has to be one of the subclass of <code class="xref py py-class docutils literal notranslate"><span class="pre">file_utils.file_utils.ResourceProcessor</span></code>.</p></li>
</ul>
<p>Examples:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 57%" />
<col style="width: 5%" />
<col style="width: 11%" />
<col style="width: 26%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>file_id</p></th>
<th class="head"><p>name</p></th>
<th class="head"><p>source</p></th>
<th class="head"><p>processor</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>resources://MSCOCO</p></td>
<td><p>MSCOCO</p></td>
<td><p>default(amazon)</p></td>
<td><p>Default(MSCOCOResourceProcessor)</p></td>
</tr>
<tr class="row-odd"><td><p>resources://MSCOCO&#64;tsinghua</p></td>
<td><p>MSCOCO</p></td>
<td><p>tsinghua</p></td>
<td><p>Default(MSCOCOResourceProcessor)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://cotk-data.s3-ap-northeast-1.amazonaws.com/mscoco.zip#MSCOCO">https://cotk-data.s3-ap-northeast-1.amazonaws.com/mscoco.zip#MSCOCO</a></p></td>
<td><p>MSCOCO</p></td>
<td><p>None</p></td>
<td><p>MSCOCOResourceProcessor</p></td>
</tr>
<tr class="row-odd"><td><p>./mscoco.zip#MSCOCO</p></td>
<td><p>MSCOCO</p></td>
<td><p>None</p></td>
<td><p>MSCOCOResourceProcessor</p></td>
</tr>
</tbody>
</table>
<div class="section" id="download-import-resources-manually">
<h3>Download / Import Resources Manually<a class="headerlink" href="#download-import-resources-manually" title="Permalink to this headline">¶</a></h3>
<p>If you want to use CoTK resources in an offline environment,
you can download resources and import them to cotk manually.</p>
<ul class="simple">
<li><p>The download urls are placed under <code class="docutils literal notranslate"><span class="pre">./cotk/resource_config</span></code>, see <a class="reference internal" href="notes/extend.html#resources-desc"><span class="std std-ref">Resource Configs</span></a>.</p></li>
<li><p>The following command can import a local file of resources into cache:</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cotk import &lt;file_id&gt; &lt;file_path&gt;
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">file_id</span></code> should start with <code class="docutils literal notranslate"><span class="pre">resources://</span></code>, and <code class="docutils literal notranslate"><span class="pre">file_path</span></code> is the path to the local resource. For example:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cotk import resources://MSCOCO ./MSCOCO.zip
</pre></div>
</div>
<p>More <a class="reference internal" href="notes/cli_usage.html#cli-usage"><span class="std std-ref">CLI commands here</span></a>.</p>
<p>Predefined Resources</p>
</div>
</div>
<div class="section" id="word-vector">
<h2>Word Vector<a class="headerlink" href="#word-vector" title="Permalink to this headline">¶</a></h2>
<div class="section" id="glove50d">
<h3>Glove50d<a class="headerlink" href="#glove50d" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p>name: <code class="docutils literal notranslate"><span class="pre">Glove50d</span></code></p></li>
<li><p>processor: <code class="xref py py-class docutils literal notranslate"><span class="pre">_utils.resource_processor.Glove50dResourceProcessor</span></code></p></li>
<li><p>source: <code class="docutils literal notranslate"><span class="pre">stanford</span></code></p></li>
<li><p>used by: <a class="reference internal" href="wordvector.html#cotk.wordvector.Glove" title="cotk.wordvector.Glove"><code class="xref py py-class docutils literal notranslate"><span class="pre">wordvector.Glove</span></code></a></p></li>
</ul>
<dl>
<dt>Introduction</dt><dd><p>This is a file containing vector representation for words pretrained by <cite>GloVe</cite>, which is an unsupervised learning
algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word
co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures
of the word vector space.</p>
<p>This file is a 50 dimension version from <code class="docutils literal notranslate"><span class="pre">glove.6B</span></code>, which is trained on <cite>Wikipedia2014</cite> and <cite>Gigaword5</cite>.</p>
</dd>
<dt>Statistic</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 60%" />
<col style="width: 40%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Dimension</p></td>
<td><p>50</p></td>
</tr>
<tr class="row-odd"><td><p>Vocabulary Size</p></td>
<td><p>400,000</p></td>
</tr>
</tbody>
</table>
</dd>
<dt>Reference</dt><dd><p>[1] GloVe: Global Vectors for Word Representation. <a class="reference external" href="https://nlp.stanford.edu/projects/glove/">https://nlp.stanford.edu/projects/glove/</a></p>
<p>[2] Pennington J, Socher R, Manning C. <a class="reference external" href="https://www.aclweb.org/anthology/D14-1162">Glove: Global vectors for word representation</a>
//Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). 2014: 1532-1543.</p>
</dd>
</dl>
</div></blockquote>
</div>
<div class="section" id="glove100d">
<h3>Glove100d<a class="headerlink" href="#glove100d" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p>name: <code class="docutils literal notranslate"><span class="pre">Glove100d</span></code></p></li>
<li><p>processor: <code class="xref py py-class docutils literal notranslate"><span class="pre">_utils.resource_processor.Glove100dResourceProcessor</span></code></p></li>
<li><p>source: <code class="docutils literal notranslate"><span class="pre">stanford</span></code></p></li>
<li><p>usage: <a class="reference internal" href="wordvector.html#cotk.wordvector.Glove" title="cotk.wordvector.Glove"><code class="xref py py-class docutils literal notranslate"><span class="pre">wordvector.Glove</span></code></a></p></li>
</ul>
<dl>
<dt>Introduction</dt><dd><ul class="simple">
<li><p>This is a file containing vector representation for words pretrained by <cite>GloVe</cite>.</p></li>
<li><p>This file is a 100 dimension version from <code class="docutils literal notranslate"><span class="pre">glove.6B</span></code>.</p></li>
<li><p>Refer to <a class="reference internal" href="#glove50d">Glove50d</a> for more information and references.</p></li>
</ul>
</dd>
<dt>Statistic</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 60%" />
<col style="width: 40%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Dimension</p></td>
<td><p>100</p></td>
</tr>
<tr class="row-odd"><td><p>Vocabulary Size</p></td>
<td><p>400,000</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
</div></blockquote>
</div>
<div class="section" id="glove200d">
<h3>Glove200d<a class="headerlink" href="#glove200d" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p>name: <code class="docutils literal notranslate"><span class="pre">Glove200d</span></code></p></li>
<li><p>processor: <code class="xref py py-class docutils literal notranslate"><span class="pre">_utils.resource_processor.Glove200dResourceProcessor</span></code></p></li>
<li><p>source: <code class="docutils literal notranslate"><span class="pre">stanford</span></code></p></li>
<li><p>usage: <a class="reference internal" href="wordvector.html#cotk.wordvector.Glove" title="cotk.wordvector.Glove"><code class="xref py py-class docutils literal notranslate"><span class="pre">wordvector.Glove</span></code></a></p></li>
</ul>
<dl>
<dt>Introduction</dt><dd><ul class="simple">
<li><p>This is a file containing vector representation for words pretrained by <cite>GloVe</cite>.</p></li>
<li><p>This file is a 200 dimension version from <code class="docutils literal notranslate"><span class="pre">glove.6B</span></code>.</p></li>
<li><p>Refer to <a class="reference internal" href="#glove50d">Glove50d</a> for more information and references.</p></li>
</ul>
</dd>
<dt>Statistic</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 60%" />
<col style="width: 40%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Dimension</p></td>
<td><p>200</p></td>
</tr>
<tr class="row-odd"><td><p>Vocabulary Size</p></td>
<td><p>400,000</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
</div></blockquote>
</div>
<div class="section" id="glove300d">
<h3>Glove300d<a class="headerlink" href="#glove300d" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p>name: <code class="docutils literal notranslate"><span class="pre">Glove300d</span></code></p></li>
<li><p>processor: <code class="xref py py-class docutils literal notranslate"><span class="pre">_utils.resource_processor.Glove300dResourceProcessor</span></code></p></li>
<li><p>source: <code class="docutils literal notranslate"><span class="pre">stanford</span></code></p></li>
<li><p>usage: <a class="reference internal" href="wordvector.html#cotk.wordvector.Glove" title="cotk.wordvector.Glove"><code class="xref py py-class docutils literal notranslate"><span class="pre">wordvector.Glove</span></code></a></p></li>
</ul>
<dl>
<dt>Introduction</dt><dd><ul class="simple">
<li><p>This is a file containing vector representation for words pretrained by <cite>GloVe</cite>.</p></li>
<li><p>This file is a 300 dimension version from <code class="docutils literal notranslate"><span class="pre">glove.6B</span></code>.</p></li>
<li><p>Refer to <a class="reference internal" href="#glove50d">Glove50d</a> for more information and references.</p></li>
</ul>
</dd>
<dt>Statistic</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 60%" />
<col style="width: 40%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Dimension</p></td>
<td><p>300</p></td>
</tr>
<tr class="row-odd"><td><p>Vocabulary Size</p></td>
<td><p>40,000</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
</div></blockquote>
</div>
<div class="section" id="glove50d-small">
<h3>Glove50d_small<a class="headerlink" href="#glove50d-small" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p>name: <code class="docutils literal notranslate"><span class="pre">Glove50d_small</span></code></p></li>
<li><p>processor: <code class="xref py py-class docutils literal notranslate"><span class="pre">_utils.resource_processor.Glove50dResourceProcessor</span></code></p></li>
<li><p>source: <code class="docutils literal notranslate"><span class="pre">amazon</span></code></p></li>
<li><p>usage: <a class="reference internal" href="wordvector.html#cotk.wordvector.Glove" title="cotk.wordvector.Glove"><code class="xref py py-class docutils literal notranslate"><span class="pre">wordvector.Glove</span></code></a></p></li>
</ul>
<dl>
<dt>Introduction</dt><dd><ul class="simple">
<li><p>This is a file containing vector representation for words pretrained by <cite>GloVe</cite>.</p></li>
<li><p>This file is a 50 dimension version from <code class="docutils literal notranslate"><span class="pre">glove.6B</span></code> and only contains the most frequency 40,000 words.</p></li>
<li><p>Refer to <a class="reference internal" href="#glove50d">Glove50d</a> for more information and references.</p></li>
</ul>
</dd>
<dt>Statistic</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 60%" />
<col style="width: 40%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Dimension</p></td>
<td><p>50</p></td>
</tr>
<tr class="row-odd"><td><p>Vocabulary Size</p></td>
<td><p>40,000</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
</div></blockquote>
</div>
</div>
<div class="section" id="datasets">
<h2>Datasets<a class="headerlink" href="#datasets" title="Permalink to this headline">¶</a></h2>
<div class="section" id="mscoco">
<h3>MSCOCO<a class="headerlink" href="#mscoco" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p>name: <code class="docutils literal notranslate"><span class="pre">MSCOCO</span></code></p></li>
<li><p>processor: <code class="xref py py-class docutils literal notranslate"><span class="pre">_utils.resource_processor.MSCOCOResourceProcessor</span></code></p></li>
<li><p>source: <code class="docutils literal notranslate"><span class="pre">amazon</span></code>, <code class="docutils literal notranslate"><span class="pre">tsinghua</span></code></p></li>
<li><p>usage: <a class="reference internal" href="dataloader.html#cotk.dataloader.MSCOCO" title="cotk.dataloader.MSCOCO"><code class="xref py py-class docutils literal notranslate"><span class="pre">dataloader.MSCOCO</span></code></a></p></li>
</ul>
<dl>
<dt>Introduction</dt><dd><p>MSCOCO is a new dataset gathering images of complex everyday scenes containing common objects
in their natural context. We neglect the images and just employ the corresponding caption.</p>
<p>The original data is <a class="reference external" href="http://images.cocodataset.org/annotations/annotations_trainval2017.zip">2017 Train/Val annotations [241MB]</a> .
We use the same train set as original data, but split the val set into dev(odd-numbered sentences) and test set(even-numbered sentences).
We extract the caption and use <code class="docutils literal notranslate"><span class="pre">nltk.tokenize.word_tokenize</span></code> for tokenization.
We also capitalize each sentence and add full stop to it if it does not have one.</p>
</dd>
<dt>Statistic</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 67%" />
<col style="width: 12%" />
<col style="width: 11%" />
<col style="width: 11%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"><p>Train</p></th>
<th class="head"><p>Dev</p></th>
<th class="head"><p>Test</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Numbers of Sentences</p></td>
<td><p>591,753</p></td>
<td><p>12,507</p></td>
<td><p>12,507</p></td>
</tr>
<tr class="row-odd"><td><p>Minimum length of Sentences</p></td>
<td><p>8</p></td>
<td><p>10</p></td>
<td><p>10</p></td>
</tr>
<tr class="row-even"><td><p>Maximum length of Sentences</p></td>
<td><p>50</p></td>
<td><p>48</p></td>
<td><p>50</p></td>
</tr>
<tr class="row-odd"><td><p>Average length of Sentences</p></td>
<td><p>13.55</p></td>
<td><p>13.55</p></td>
<td><p>12.52</p></td>
</tr>
<tr class="row-even"><td><p>Std Deviation of Length of Sentences</p></td>
<td><p>2.51</p></td>
<td><p>2.44</p></td>
<td><p>2.44</p></td>
</tr>
<tr class="row-odd"><td><p>Vocabulary Size</p></td>
<td><p>33,241</p></td>
<td><p>5,950</p></td>
<td><p>5,869</p></td>
</tr>
<tr class="row-even"><td><p>Frequency Vocabulary Size (times&gt;=10)</p></td>
<td><p>8,064</p></td>
<td><p>1,050</p></td>
<td><p>1,034</p></td>
</tr>
</tbody>
</table>
</dd>
<dt>Reference</dt><dd><p>[1] COCO: Common Objects in Context. <a class="reference external" href="http://cocodataset.org">http://cocodataset.org</a></p>
<p>[2] Chen X, Fang H, Lin T Y, et al. <a class="reference external" href="https://arxiv.org/pdf/1504.00325.pdf">Microsoft COCO Captions: Data Collection and Evaluation Server</a>.
arXiv:1504.00325, 2015.</p>
</dd>
</dl>
</div></blockquote>
</div>
<div class="section" id="mscoco-small">
<h3>MSCOCO_small<a class="headerlink" href="#mscoco-small" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p>name: <code class="docutils literal notranslate"><span class="pre">MSCOCO_small</span></code></p></li>
<li><p>processor: <code class="xref py py-class docutils literal notranslate"><span class="pre">_utils.resource_processor.MSCOCOResourceProcessor</span></code></p></li>
<li><p>source: <code class="docutils literal notranslate"><span class="pre">amazon</span></code></p></li>
<li><p>usage: <a class="reference internal" href="dataloader.html#cotk.dataloader.MSCOCO" title="cotk.dataloader.MSCOCO"><code class="xref py py-class docutils literal notranslate"><span class="pre">dataloader.MSCOCO</span></code></a></p></li>
</ul>
<dl>
<dt>Introduction</dt><dd><ul class="simple">
<li><p>The data is random uniformed sampled from <a class="reference internal" href="#mscoco">MSCOCO</a>.</p></li>
<li><p>Refer to <a class="reference internal" href="#mscoco">MSCOCO</a> for more information and references.</p></li>
</ul>
</dd>
<dt>Statistic</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 58%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"><p>Train</p></th>
<th class="head"><p>Dev</p></th>
<th class="head"><p>Test</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Numbers of Sentences</p></td>
<td><p>59,175</p></td>
<td><p>1,250</p></td>
<td><p>1,250</p></td>
</tr>
<tr class="row-odd"><td><p>Vocabulary Size</p></td>
<td><p>12,212</p></td>
<td><p>1,877</p></td>
<td><p>1,841</p></td>
</tr>
<tr class="row-even"><td><p>Frequency Vocabulary Size (times&gt;=10)</p></td>
<td><p>2,588</p></td>
<td><p>219</p></td>
<td><p>219</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
</div></blockquote>
</div>
<div class="section" id="opensubtitles">
<h3>OpenSubtitles<a class="headerlink" href="#opensubtitles" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p>name: <code class="docutils literal notranslate"><span class="pre">OpenSubtitles</span></code></p></li>
<li><p>processor: <code class="xref py py-class docutils literal notranslate"><span class="pre">_utils.resource_processor.OpenSubtitlesResourceProcessor</span></code></p></li>
<li><p>source: <code class="docutils literal notranslate"><span class="pre">amazon</span></code>, <code class="docutils literal notranslate"><span class="pre">tsinghua</span></code></p></li>
<li><p>usage: <a class="reference internal" href="dataloader.html#cotk.dataloader.OpenSubtitles" title="cotk.dataloader.OpenSubtitles"><code class="xref py py-class docutils literal notranslate"><span class="pre">dataloader.OpenSubtitles</span></code></a></p></li>
</ul>
<dl>
<dt>Introduction</dt><dd><p>Opensubtitle dataset is collected from movie subtitles.
To construct this dataset for single-turn dialogue generation,
we follow [3] and regard a pair of adjacent sentences as one dialogue turn.
We set the former sentence as a post and the latter one as the corresponding response.
We remove the pairs whose lengths are extremely long or short,
and randomly sample 1,144,949/20,000/10,000 pairs as our train/dev/test set.
The dataset is tokenized and all the tokens are in lower-case.</p>
</dd>
<dt>Statistic</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 58%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"><p>Train</p></th>
<th class="head"><p>Dev</p></th>
<th class="head"><p>Test</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Numbers of Post/Response Pairs</p></td>
<td><p>1,144,949</p></td>
<td><p>20,000</p></td>
<td><p>10,000</p></td>
</tr>
<tr class="row-odd"><td><p>Average Length (Post/Response)</p></td>
<td><p>9.08/9.10</p></td>
<td><p>9.06/9.13</p></td>
<td><p>9.04/9.05</p></td>
</tr>
<tr class="row-even"><td><p>Vocabulary Size</p></td>
<td><p>104,683</p></td>
<td><p>18,653</p></td>
<td><p>12,769</p></td>
</tr>
<tr class="row-odd"><td><p>Frequency Vocabulary Size (times&gt;=10)</p></td>
<td><p>31,039</p></td>
<td><p>2,030</p></td>
<td><p>1,241</p></td>
</tr>
</tbody>
</table>
</dd>
<dt>Reference</dt><dd><p>[1] OpenSubtitles. <a class="reference external" href="http://opus.nlpl.eu/OpenSubtitles.php">http://opus.nlpl.eu/OpenSubtitles.php</a></p>
<p>[2] J. Tiedemann, 2016, <a class="reference external" href="http://www.lrec-conf.org/proceedings/lrec2016/pdf/62_Paper.pdf">Finding Alternative Translations in a Large Corpus of Movie Subtitles</a>.
In Proceedings of the 10th International Conference on Language Resources and Evaluation (LREC 2016)</p>
<p>[3] Vinyals O, Le Q. <a class="reference external" href="https://arxiv.org/pdf/1506.05869.pdf">A Neural Conversational Model</a>. arXiv preprint arXiv:1506.05869, 2015.</p>
</dd>
</dl>
</div></blockquote>
</div>
<div class="section" id="opensubtitles-small">
<h3>OpenSubtitles_small<a class="headerlink" href="#opensubtitles-small" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p>name: <code class="docutils literal notranslate"><span class="pre">OpenSubtitles_small</span></code></p></li>
<li><p>processor: <code class="xref py py-class docutils literal notranslate"><span class="pre">_utils.resource_processor.OpenSubtitlesResourceProcessor</span></code></p></li>
<li><p>source: <code class="docutils literal notranslate"><span class="pre">amazon</span></code></p></li>
<li><p>usage: <a class="reference internal" href="dataloader.html#cotk.dataloader.OpenSubtitles" title="cotk.dataloader.OpenSubtitles"><code class="xref py py-class docutils literal notranslate"><span class="pre">dataloader.OpenSubtitles</span></code></a></p></li>
</ul>
<dl>
<dt>Introduction</dt><dd><ul class="simple">
<li><p>The data is random uniformed sampled from <a class="reference internal" href="#opensubtitles">OpenSubtitles</a>.</p></li>
<li><p>Refer to <a class="reference internal" href="#opensubtitles">OpenSubtitles</a> for more information and references.</p></li>
</ul>
</dd>
<dt>Statistic</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 58%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"><p>Train</p></th>
<th class="head"><p>Dev</p></th>
<th class="head"><p>Test</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Numbers of Post/Response Pairs</p></td>
<td><p>11,449</p></td>
<td><p>2,000</p></td>
<td><p>1,000</p></td>
</tr>
<tr class="row-odd"><td><p>Vocabulary Size</p></td>
<td><p>13,984</p></td>
<td><p>4,661</p></td>
<td><p>3,079</p></td>
</tr>
<tr class="row-even"><td><p>Frequency Vocabulary Size (times&gt;=10)</p></td>
<td><p>1,333</p></td>
<td><p>367</p></td>
<td><p>211</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
</div></blockquote>
</div>
<div class="section" id="sst">
<h3>SST<a class="headerlink" href="#sst" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p>name: <code class="docutils literal notranslate"><span class="pre">SST</span></code></p></li>
<li><p>processor: <code class="xref py py-class docutils literal notranslate"><span class="pre">_utils.resource_processor.SSTResourceProcessor</span></code></p></li>
<li><p>source: <code class="docutils literal notranslate"><span class="pre">stanford</span></code></p></li>
<li><p>usage: <a class="reference internal" href="dataloader.html#cotk.dataloader.SST" title="cotk.dataloader.SST"><code class="xref py py-class docutils literal notranslate"><span class="pre">dataloader.SST</span></code></a></p></li>
</ul>
<dl>
<dt>Introduction</dt><dd><p>Stanford Sentiment Treebank is the first corpus with fully labeled
parse trees that allows for a complete analysis of the compositional
effects of sentiment in language.</p>
<p>We remain the original split of dataset. The dataset is tokenized and
contains capitalized letters.</p>
</dd>
<dt>Statistic</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 58%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"><p>Train</p></th>
<th class="head"><p>Dev</p></th>
<th class="head"><p>Test</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Numbers of Sentences</p></td>
<td><p>8,544</p></td>
<td><p>1,101</p></td>
<td><p>2,210</p></td>
</tr>
<tr class="row-odd"><td><p>Average Length</p></td>
<td><p>19.14</p></td>
<td><p>19.32</p></td>
<td><p>19.19</p></td>
</tr>
<tr class="row-even"><td><p>Vocabulary Size</p></td>
<td><p>16,586</p></td>
<td><p>5,043</p></td>
<td><p>7,934</p></td>
</tr>
<tr class="row-odd"><td><p>Frequency Vocabulary Size (times&gt;=10)</p></td>
<td><p>1,685</p></td>
<td><p>232</p></td>
<td><p>441</p></td>
</tr>
</tbody>
</table>
</dd>
<dt>Reference</dt><dd><p>[1] Recursive Deep Model for Sematic Compositionality over a Sentiment Treebank. <a class="reference external" href="https://nlp.stanford.edu/sentiment/">https://nlp.stanford.edu/sentiment/</a></p>
<p>[2] Socher R, Perelygin A, Wu J, et al.
<a class="reference external" href="https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf">Recursive deep models for semantic compositionality over a sentiment treebank</a>
//Proceedings of the 2013 conference on empirical methods in natural language processing. 2013: 1631-1642.</p>
</dd>
</dl>
</div></blockquote>
</div>
<div class="section" id="switchboardcorpus">
<h3>SwitchboardCorpus<a class="headerlink" href="#switchboardcorpus" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p>name: <code class="docutils literal notranslate"><span class="pre">SwitchboardCorpus</span></code></p></li>
<li><p>processor: <code class="xref py py-class docutils literal notranslate"><span class="pre">_utils.resource_processor.SwitchboardCorpusResourceProcessor</span></code></p></li>
<li><p>source: <code class="docutils literal notranslate"><span class="pre">amazon</span></code></p></li>
<li><p>usage: <a class="reference internal" href="dataloader.html#cotk.dataloader.SwitchboardCorpus" title="cotk.dataloader.SwitchboardCorpus"><code class="xref py py-class docutils literal notranslate"><span class="pre">dataloader.SwitchboardCorpus</span></code></a></p></li>
</ul>
<dl>
<dt>Introduction</dt><dd><p>Switchboard is a collection of about 2,400 two-sided telephone conversations among
543 speakers (302 male, 241 female) from all areas of the United States.
A computer-driven robot operator system handled the calls, giving the caller
appropriate recorded prompts, selecting and dialing another person (the callee) to
take part in a conversation, introducing a topic for discussion and recording the
speech from the two subjects into separate channels until the conversation was finished.
About 70 topics were provided, of which about 50 were used frequently. Selection of topics
and callees was constrained so that: (1) no two speakers would converse together more than
once and (2) no one spoke more than once on a given topic.</p>
<p>We introduce the data processed by Zhao, Ran and Eskenazi[4], which construct the set
<code class="docutils literal notranslate"><span class="pre">multi_ref</span></code> for one-to-many dialog evaluation (One context, multiple responses).
<code class="docutils literal notranslate"><span class="pre">multi_ref</span></code> was constructed by extracting multiple responses for single context
with retrieval method and annotation on the other test set. For the details, please refer
to [4].</p>
<p>We used their training set, dev set and test set. That is, capitalization,
tokenization, splits of dataset and any other aspects of our data are the
same as theirs (in their version, utterances are lowercase and are not tokenized).</p>
<p>However, there are two differences between our data with theirs:</p>
<ul class="simple">
<li><p>We ensure that any two consecutive utterances come from different speakers,
by concatenating the original consecutive utterances from the same speakers
during pre-processing of <a class="reference internal" href="dataloader.html#cotk.dataloader.SwitchboardCorpus" title="cotk.dataloader.SwitchboardCorpus"><code class="xref py py-class docutils literal notranslate"><span class="pre">dataloader.SwitchboardCorpus</span></code></a>.
(This is because we want to be compatible with other multi-turn dialog set.)</p></li>
<li><p>To avoid the gap between training and test, we have to remove some samples
from <code class="docutils literal notranslate"><span class="pre">multi_ref</span></code>, where the target speaker is the same as the last one in the context.</p></li>
</ul>
</dd>
<dt>Statistic</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 72%" />
<col style="width: 11%" />
<col style="width: 9%" />
<col style="width: 9%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"><p>Train</p></th>
<th class="head"><p>Dev</p></th>
<th class="head"><p>Test</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Numbers of Sessions</p></td>
<td><p>2,316</p></td>
<td><p>60</p></td>
<td><p>62</p></td>
</tr>
<tr class="row-odd"><td><p>Minimum Number of Turns (per session)</p></td>
<td><p>3</p></td>
<td><p>19</p></td>
<td><p>8</p></td>
</tr>
<tr class="row-even"><td><p>Maximum Number of Turns (per session)</p></td>
<td><p>190</p></td>
<td><p>144</p></td>
<td><p>148</p></td>
</tr>
<tr class="row-odd"><td><p>Average Number of Turns (per session)</p></td>
<td><p>59.47</p></td>
<td><p>58.92</p></td>
<td><p>58.95</p></td>
</tr>
<tr class="row-even"><td><p>Std Deviation of Number of Turns</p></td>
<td><p>27.50</p></td>
<td><p>26.91</p></td>
<td><p>32.43</p></td>
</tr>
<tr class="row-odd"><td><p>Minimum Length of Sentences</p></td>
<td><p>3</p></td>
<td><p>3</p></td>
<td><p>3</p></td>
</tr>
<tr class="row-even"><td><p>Maximum Length of Sentences</p></td>
<td><p>401</p></td>
<td><p>185</p></td>
<td><p>333</p></td>
</tr>
<tr class="row-odd"><td><p>Average Length of Sentences</p></td>
<td><p>19.03</p></td>
<td><p>19.12</p></td>
<td><p>20.15</p></td>
</tr>
<tr class="row-even"><td><p>Std Deviation of Number of Sentences</p></td>
<td><p>20.25</p></td>
<td><p>19.65</p></td>
<td><p>21.59</p></td>
</tr>
<tr class="row-odd"><td><p>Vocabulary Size</p></td>
<td><p>24,719</p></td>
<td><p>7,704</p></td>
<td><p>6,203</p></td>
</tr>
<tr class="row-even"><td><p>Frequency Vocabulary Size (times&gt;=10)</p></td>
<td><p>9,508</p></td>
<td><p>1,021</p></td>
<td><p>1,095</p></td>
</tr>
</tbody>
</table>
</dd>
<dt>Reference</dt><dd><p>[1] Switchboard-1 release 2. <a class="reference external" href="https://catalog.ldc.upenn.edu/LDC97S62">https://catalog.ldc.upenn.edu/LDC97S62</a></p>
<p>[2] John J G and Edward H. <a class="reference external" href="https://catalog.ldc.upenn.edu/LDC97S62">Switchboard-1 release 2</a>. Linguistic Data Consortium, Philadelphia 1997.</p>
<p>[3] NeuralDialog-CVAE. <a class="reference external" href="https://github.com/snakeztc/NeuralDialog-CVAE">https://github.com/snakeztc/NeuralDialog-CVAE</a></p>
<p>[4] Zhao, Tiancheng and Zhao, Ran and Eskenazi, Maxine. Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders. ACL 2017.</p>
</dd>
</dl>
</div></blockquote>
</div>
<div class="section" id="switchboardcorpus-small">
<h3>SwitchboardCorpus_small<a class="headerlink" href="#switchboardcorpus-small" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p>name: <code class="docutils literal notranslate"><span class="pre">SwitchboardCorpus_small</span></code></p></li>
<li><p>processor: <code class="xref py py-class docutils literal notranslate"><span class="pre">_utils.resource_processor.SwitchboardCorpusResourceProcessor</span></code></p></li>
<li><p>source: <code class="docutils literal notranslate"><span class="pre">amazon</span></code></p></li>
<li><p>usage: <a class="reference internal" href="dataloader.html#cotk.dataloader.SwitchboardCorpus" title="cotk.dataloader.SwitchboardCorpus"><code class="xref py py-class docutils literal notranslate"><span class="pre">dataloader.SwitchboardCorpus</span></code></a></p></li>
</ul>
<dl>
<dt>Introduction</dt><dd><ul class="simple">
<li><p>The data is random uniformed sampled from <a class="reference internal" href="#switchboardcorpus">SwitchboardCorpus</a>.</p></li>
<li><p>Refer to <a class="reference internal" href="#switchboardcorpus">SwitchboardCorpus</a> for details and references.</p></li>
</ul>
</dd>
<dt>Statistic</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 58%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"><p>Train</p></th>
<th class="head"><p>Dev</p></th>
<th class="head"><p>Test</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Numbers of Sessions</p></td>
<td><p>463</p></td>
<td><p>12</p></td>
<td><p>12</p></td>
</tr>
<tr class="row-odd"><td><p>Vocabulary Size</p></td>
<td><p>13,235</p></td>
<td><p>5,189</p></td>
<td><p>4,729</p></td>
</tr>
<tr class="row-even"><td><p>Frequency Vocabulary Size (times&gt;=10)</p></td>
<td><p>3,923</p></td>
<td><p>341</p></td>
<td><p>317</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
</div></blockquote>
</div>
<div class="section" id="ubuntu">
<h3>Ubuntu<a class="headerlink" href="#ubuntu" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p>name: <code class="docutils literal notranslate"><span class="pre">Ubuntu</span></code></p></li>
<li><p>processor: <code class="xref py py-class docutils literal notranslate"><span class="pre">_utils.resource_processor.UbuntuResourceProcessor</span></code></p></li>
<li><p>source: <code class="docutils literal notranslate"><span class="pre">amazon</span></code>, <code class="docutils literal notranslate"><span class="pre">tsinghua</span></code></p></li>
<li><p>usage: <a class="reference internal" href="dataloader.html#cotk.dataloader.UbuntuCorpus" title="cotk.dataloader.UbuntuCorpus"><code class="xref py py-class docutils literal notranslate"><span class="pre">dataloader.UbuntuCorpus</span></code></a></p></li>
</ul>
<dl>
<dt>Introduction</dt><dd><p>Ubuntu Dialogue Corpus 2.0 is a dataset containing a mass of multi-turn dialogues.
The dataset has both the multi-turn property of conversations in the Dialog State Tracking Challenge datasets,
and the unstructured nature of interactions from microblog services such as Twitter.</p>
<p>We build the dataset using the ubuntu-ranking-dataset-creator[1], without tokenization, lemmatization or stemming.
The dataset contains capital character. The positive example probability is set to 1.0 for training set.
The examples for training/dev/test sets are set to 1,000,000/19,560/18,920 as default.
Other settings are default.</p>
</dd>
<dt>Statistic</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 54%" />
<col style="width: 18%" />
<col style="width: 18%" />
<col style="width: 10%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"><p>Train</p></th>
<th class="head"><p>Dev</p></th>
<th class="head"><p>Test</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Numbers of Sessions</p></td>
<td><p>1,000,000</p></td>
<td><p>19,560</p></td>
<td><p>18,920</p></td>
</tr>
<tr class="row-odd"><td><p>Minimum Number of Turns (per session)</p></td>
<td><p>3</p></td>
<td><p>3</p></td>
<td><p>3</p></td>
</tr>
<tr class="row-even"><td><p>Maximum Number of Turns (per session)</p></td>
<td><p>19</p></td>
<td><p>19</p></td>
<td><p>19</p></td>
</tr>
<tr class="row-odd"><td><p>Average Number of Turns (per session)</p></td>
<td><p>4.95</p></td>
<td><p>4.79</p></td>
<td><p>4.85</p></td>
</tr>
<tr class="row-even"><td><p>Std Deviation of Number of Turns</p></td>
<td><p>2.97</p></td>
<td><p>2.79</p></td>
<td><p>2.85</p></td>
</tr>
<tr class="row-odd"><td><p>Minimum Length of Sentences</p></td>
<td><p>2</p></td>
<td><p>2</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-even"><td><p>Maximum Length of Sentences</p></td>
<td><p>977</p></td>
<td><p>343</p></td>
<td><p>817</p></td>
</tr>
<tr class="row-odd"><td><p>Average Length of Sentences</p></td>
<td><p>17.98</p></td>
<td><p>19.40</p></td>
<td><p>19.61</p></td>
</tr>
<tr class="row-even"><td><p>Std Deviation of Number of Sentences</p></td>
<td><p>16.26</p></td>
<td><p>17.25</p></td>
<td><p>17.94</p></td>
</tr>
<tr class="row-odd"><td><p>Vocabulary Size</p></td>
<td><p>576,693</p></td>
<td><p>47,288</p></td>
<td><p>47,847</p></td>
</tr>
<tr class="row-even"><td><p>Frequency Vocabulary Size (times&gt;=10)</p></td>
<td><p>23,498</p></td>
<td><p>2,568</p></td>
<td><p>2,565</p></td>
</tr>
</tbody>
</table>
</dd>
<dt>Reference</dt><dd><p>[1] Ubuntu Dialogue Corpus v2.0. <a class="reference external" href="https://github.com/rkadlec/ubuntu-ranking-dataset-creator">https://github.com/rkadlec/ubuntu-ranking-dataset-creator</a></p>
<p>[2] R. Lowe, N. Pow, I. Serban, and J. Pineau.
<a class="reference external" href="https://arxiv.org/pdf/1506.08909.pdf">The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems</a>.
In Special Interest Group on Discourse and Dialogue (SIGDIAL), 2015a.</p>
</dd>
</dl>
</div></blockquote>
</div>
<div class="section" id="ubuntu-small">
<h3>Ubuntu_small<a class="headerlink" href="#ubuntu-small" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p>name: <code class="docutils literal notranslate"><span class="pre">Ubuntu_small</span></code></p></li>
<li><p>processor: <code class="xref py py-class docutils literal notranslate"><span class="pre">_utils.resource_processor.UbuntuResourceProcessor</span></code></p></li>
<li><p>source: <code class="docutils literal notranslate"><span class="pre">amazon</span></code></p></li>
<li><p>usage: <a class="reference internal" href="dataloader.html#cotk.dataloader.UbuntuCorpus" title="cotk.dataloader.UbuntuCorpus"><code class="xref py py-class docutils literal notranslate"><span class="pre">dataloader.UbuntuCorpus</span></code></a></p></li>
</ul>
<dl>
<dt>Introduction</dt><dd><ul class="simple">
<li><p>The data is random uniformed sampled from <a class="reference internal" href="#ubuntu">Ubuntu</a>.</p></li>
<li><p>Refer to <a class="reference internal" href="#ubuntu">Ubuntu</a> for details and references.</p></li>
</ul>
</dd>
<dt>Statistic</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 58%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property</p></th>
<th class="head"><p>Train</p></th>
<th class="head"><p>Dev</p></th>
<th class="head"><p>Test</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Numbers of Sessions</p></td>
<td><p>10,001</p></td>
<td><p>1,957</p></td>
<td><p>1,893</p></td>
</tr>
<tr class="row-odd"><td><p>Vocabulary Size</p></td>
<td><p>32,941</p></td>
<td><p>12,348</p></td>
<td><p>12,090</p></td>
</tr>
<tr class="row-even"><td><p>Frequency Vocabulary Size (times&gt;=10)</p></td>
<td><p>1,590</p></td>
<td><p>501</p></td>
<td><p>475</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
</div></blockquote>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="file_utils.html" class="btn btn-neutral float-right" title="file_utils" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="metric.html" class="btn btn-neutral float-left" title="Metric" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, thu-coai

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>