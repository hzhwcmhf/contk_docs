

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Practice: Implement a GRU Language Model &mdash; cotk  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/cotk_theme.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="CLI Usage" href="cli_usage.html" />
    <link rel="prev" title="Quick Start" href="quickstart.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> cotk
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quick Start</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Practice: Implement a GRU Language Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#preparing-the-data">Preparing the data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#training-models">Training models</a></li>
<li class="toctree-l2"><a class="reference internal" href="#evaluations">Evaluations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#teacher-forcing">Teacher Forcing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#free-run">Free Run</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hash-value">Hash value</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#additional-word-vector">Additional: Word Vector</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cli_usage.html">CLI Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="extend.html">Extending Cotk: More Data, More Metrics!</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html">Frequently Asked Questions</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dataloader.html">Data Loader</a></li>
<li class="toctree-l1"><a class="reference internal" href="../wordvector.html">Word Vector</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metric.html">Metric</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources.html">Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../file_utils.html">file_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../file_utils.html#resources-processor">resources_processor</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Zoo</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../models/LanguageGeneration/index.html">LanguageGeneration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/SingleTurnDialog/index.html">SingleTurnDialog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/MultiTurnDialog/index.html">MultiTurnDialog</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">cotk</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Practice: Implement a GRU Language Model</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/notes/tutorial_core.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="practice-implement-a-gru-language-model">
<h1>Practice: Implement a GRU Language Model<a class="headerlink" href="#practice-implement-a-gru-language-model" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, we will train a neural language model on MSCOCO dataset.
We will focus on how to use <code class="docutils literal notranslate"><span class="pre">cotk</span></code> rather than the neural networks,
so we assume you have known how to construct a neural network.</p>
<p>After reading this tutorial, you may know:</p>
<ul class="simple">
<li><p>How to use <a class="reference internal" href="../dataloader.html#module-cotk.dataloader" title="cotk.dataloader"><code class="xref py py-mod docutils literal notranslate"><span class="pre">cotk.dataloader</span></code></a> downloading and loading dataset.</p></li>
<li><p>How to train model with the support of <code class="docutils literal notranslate"><span class="pre">cotk</span></code>.</p></li>
<li><p>How to use <a class="reference internal" href="../metric.html#module-cotk.metric" title="cotk.metric"><code class="xref py py-mod docutils literal notranslate"><span class="pre">cotk.metric</span></code></a> evaluating models.</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">cotk</span></code> does <strong>not</strong> rely on any deep learning framework,
so you can even use shallow models like ngram language model.
However, this tutorial constructs neural networks with
<code class="docutils literal notranslate"><span class="pre">pytorch</span></code>, so make sure you have installed the following package:</p>
<ul class="simple">
<li><p>Python &gt;= 3.5</p></li>
<li><p>cotk &gt;= 0.1.0</p></li>
<li><p>pytorch &gt;= 1.0.0</p></li>
<li><p>livelossplot (optional, just for showing loss)</p></li>
</ul>
<p><strong>Source codes</strong></p>
<p>You can click <a class="reference external" href="https://github.com/thu-coai/cotk/blob/master/docs/source/notes/tutorial_core_1.ipynb">here</a> for the following ipynb files.
You can also run <a class="reference external" href="http://colab.research.google.com/github/thu-coai/cotk/blob/master/docs/source/notes/tutorial_core_1.ipynb">the code</a>
<strong>online</strong> on google colab without installing any packages.</p>
<div class="section" id="preparing-the-data">
<h2>Preparing the data<a class="headerlink" href="#preparing-the-data" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">cotk</span></code> provides <a class="reference internal" href="../dataloader.html#module-cotk.dataloader" title="cotk.dataloader"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dataloader</span></code></a> to download, import and preprocess data.
Therefore, we first construct a <a class="reference internal" href="../dataloader.html#cotk.dataloader.MSCOCO" title="cotk.dataloader.MSCOCO"><code class="xref py py-class docutils literal notranslate"><span class="pre">cotk.dataloader.MSCOCO</span></code></a> to load MSCOCO dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">cotk.dataloader</span> <span class="kn">import</span> <span class="n">MSCOCO</span>
<span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">MSCOCO</span><span class="p">(</span><span class="s2">&quot;resources://MSCOCO_small&quot;</span><span class="p">)</span> <span class="c1"># &quot;resources://MSCOCO_small&quot; is a predefined resources name</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Vocab Size:&quot;</span><span class="p">,</span> <span class="n">dataloader</span><span class="o">.</span><span class="n">frequent_vocab_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;First 10 tokens:&quot;</span><span class="p">,</span>  <span class="n">dataloader</span><span class="o">.</span><span class="n">frequent_vocab_list</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dataset is split into:&quot;</span><span class="p">,</span> <span class="n">dataloader</span><span class="o">.</span><span class="n">fields</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">dataloader</span><span class="o">.</span><span class="n">get_batch</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># get the sample of id 0</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataloader</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;sent&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>INFO: downloading resources
INFO: name: MSCOCO_small
INFO: source: default
INFO: url: https://cotk-data.s3-ap-northeast-1.amazonaws.com/mscoco_small.zip
INFO: processor: MSCOCO
100%|██████████| 1020154/1020154 [00:00&lt;00:00, 1265532.43B/s]INFO: resource cached at /root/.cotk_cache/bd12bbf8ce8b157cf620e929bb36379443876ad115951dfeafb63d50b280cff2_temp

Vocab Size: 2597
First 10 tokens: [&#39;&lt;pad&gt;&#39;, &#39;&lt;unk&gt;&#39;, &#39;&lt;go&gt;&#39;, &#39;&lt;eos&gt;&#39;, &#39;.&#39;, &#39;a&#39;, &#39;A&#39;, &#39;on&#39;, &#39;of&#39;, &#39;in&#39;]
Dataset is split into: dict_keys([&#39;train&#39;, &#39;dev&#39;, &#39;test&#39;])
{&#39;sent&#39;: array([[  2,   6,  67, 653, 550,  11,   5,  65,  89,  10, 115, 352,  83,
          4,   3]]),
 &#39;sent_allvocabs&#39;: array([[  2,   6,  67, 653, 550,  11,   5,  65,  89,  10, 115, 352,  83,
          4,   3]]),
 &#39;sent_length&#39;: array([15]),
 &#39;sent_str&#39;: [&#39;A blue lamp post with a sign for the yellow brick road .&#39;]}
[&#39;A&#39;, &#39;blue&#39;, &#39;lamp&#39;, &#39;post&#39;, &#39;with&#39;, &#39;a&#39;, &#39;sign&#39;, &#39;for&#39;, &#39;the&#39;, &#39;yellow&#39;, &#39;brick&#39;, &#39;road&#39;, &#39;.&#39;]
</pre></div>
</div>
<p><a class="reference internal" href="../dataloader.html#cotk.dataloader.MSCOCO" title="cotk.dataloader.MSCOCO"><code class="xref py py-class docutils literal notranslate"><span class="pre">cotk.dataloader.MSCOCO</span></code></a> has helped us construct vocabulary list and
turn the sentences into index representation.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can also import dataset from url (<a class="reference external" href="http://test.com/data.zip">http://test.com/data.zip</a>) or
local path (./data.zip), as long as the format of the data is suitable.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You may find <code class="docutils literal notranslate"><span class="pre">data</span></code> contains similiar key <code class="docutils literal notranslate"><span class="pre">sent</span></code> and <code class="docutils literal notranslate"><span class="pre">sent_allvocabs</span></code>.
The difference between them is that <code class="docutils literal notranslate"><span class="pre">sent</span></code> only contains
<a class="reference internal" href="../dataloader.html#vocabulary-ref"><span class="std std-ref">valid vocabularies</span></a> and
<code class="docutils literal notranslate"><span class="pre">sent_allvocabs</span></code> contains both <a class="reference internal" href="../dataloader.html#vocabulary-ref"><span class="std std-ref">valid vocabularies</span></a> and
<a class="reference internal" href="../dataloader.html#vocabulary-ref"><span class="std std-ref">invalid vocabularies</span></a>.</p>
</div>
</div>
<div class="section" id="training-models">
<h2>Training models<a class="headerlink" href="#training-models" title="Permalink to this headline">¶</a></h2>
<p>First we construct a simple GRU Language model using <code class="docutils literal notranslate"><span class="pre">pytorch</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="n">embedding_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">20</span>

<span class="k">class</span> <span class="nc">LanguageModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">dataloader</span><span class="o">.</span><span class="n">frequent_vocab_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">embedding_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">dataloader</span><span class="o">.</span><span class="n">frequent_vocab_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">crossentropy</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="c1"># data is the dict returned by ``dataloader.get_batch``</span>
        <span class="n">sent</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;sent&#39;</span><span class="p">]</span>
        <span class="n">sent_length</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;sent_length&#39;</span><span class="p">]</span>
        <span class="c1"># sent is a LongTensor whose shape is (batch_size, max(sent_length))</span>
        <span class="c1"># sent_length is a list whose size is (batch_size)</span>

        <span class="n">incoming</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_layer</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span>
        <span class="c1"># incoming: (batch_size, max(sent_length), embedding_size)</span>
        <span class="n">incoming</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">incoming</span><span class="p">)</span>
        <span class="c1"># incoming: (batch_size, max(sent_length), hidden_size)</span>
        <span class="n">incoming</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">incoming</span><span class="p">)</span>
        <span class="c1"># incoming: (batch_size, max(sent_length), dataloader.frequent_vocab_size)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">length</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sent_length</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">length</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">crossentropy</span><span class="p">(</span><span class="n">incoming</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="n">length</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sent</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="n">length</span><span class="p">]))</span>
                <span class="c1"># every time step predict next token</span>

        <span class="n">data</span><span class="p">[</span><span class="s2">&quot;gen_log_prob&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)(</span><span class="n">incoming</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
</pre></div>
</div>
<p>If you are familiar with GRU, you can see the codes constructed a
network for predicting next token. Then, we will train our model with
the help of <code class="docutils literal notranslate"><span class="pre">cotk</span></code>. (It may takes several minutes to train the model.)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">livelossplot</span> <span class="kn">import</span> <span class="n">PlotLosses</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">LanguageModel</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-3</span><span class="p">)</span>
<span class="n">epoch_num</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">PlotLosses</span><span class="p">()</span>

<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_num</span><span class="p">):</span>
    <span class="n">loss_arr</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="o">.</span><span class="n">get_batches</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)):</span>
        <span class="c1"># convert numpy to torch.LongTensor</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;sent&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;sent&#39;</span><span class="p">])</span>
        <span class="n">net</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss_arr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">40</span><span class="p">:</span>
            <span class="k">break</span> <span class="c1"># break for shorten time of an epoch</span>
    <span class="n">plot</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss_arr</span><span class="p">)})</span>
    <span class="n">plot</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;epoch </span><span class="si">%d</span><span class="s2">/</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">epoch_num</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<img alt="../_images/training_loss.png" src="../_images/training_loss.png" />
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>loss:
training   (min:    3.161, max:    6.577, cur:    3.239)
epoch 100/100
</pre></div>
</div>
</div>
<div class="section" id="evaluations">
<h2>Evaluations<a class="headerlink" href="#evaluations" title="Permalink to this headline">¶</a></h2>
<p>How well our model can fit the data? <code class="docutils literal notranslate"><span class="pre">cotk</span></code> provides
some standard metrics for language generation model.</p>
<div class="section" id="teacher-forcing">
<h3>Teacher Forcing<a class="headerlink" href="#teacher-forcing" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">perplexity</span></code>
is a common used metric and it need the predicted distribution
over words. Recall we have set <code class="docutils literal notranslate"><span class="pre">data[&quot;gen_log_prob&quot;]</span></code> in previous
section, we use it right now.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">metric</span> <span class="o">=</span> <span class="n">dataloader</span><span class="o">.</span><span class="n">get_teacher_forcing_metric</span><span class="p">(</span><span class="n">gen_log_prob_key</span><span class="o">=</span><span class="s2">&quot;gen_log_prob&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="o">.</span><span class="n">get_batches</span><span class="p">(</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)):</span>
    <span class="c1"># convert numpy to torch.LongTensor</span>
    <span class="n">data</span><span class="p">[</span><span class="s1">&#39;sent&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;sent&#39;</span><span class="p">])</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">net</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">assert</span> <span class="s2">&quot;gen_log_prob&quot;</span> <span class="ow">in</span> <span class="n">data</span>
    <span class="n">metric</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">metric</span><span class="o">.</span><span class="n">close</span><span class="p">(),</span> <span class="n">width</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>test set restart, 78 batches and 2 left
{&#39;perplexity&#39;: 34.22552934535805, &#39;perplexity hashvalue&#39;: &#39;2cc7ecfad6f2b41949648225e043d0b2f8bcf283aae5ef773e821f641b8a9763&#39;}
</pre></div>
</div>
<p>The codes above evaluated the model in teacher forcing mode, where every input
token is the real data.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The type of <code class="docutils literal notranslate"><span class="pre">data['gen_log_prob']</span></code> is <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>, but most metrics <strong>do not</strong>
receive a tensor input as we are trying to implement a library <strong>not</strong>
depending on any deep learning framework. <a class="reference internal" href="../metric.html#cotk.metric.PerplexityMetric" title="cotk.metric.PerplexityMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">metric.PerplexityMetric</span></code></a> just use <code class="docutils literal notranslate"><span class="pre">torch</span></code>
to accelerate the calculation, a <code class="xref py py-class docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> can also be accepted.</p>
</div>
</div>
<div class="section" id="free-run">
<h3>Free Run<a class="headerlink" href="#free-run" title="Permalink to this headline">¶</a></h3>
<p>A language model can also generate sentences by sending the
generated token back to input in each step. It is called “freerun”
or “inference” mode.</p>
<p><code class="docutils literal notranslate"><span class="pre">Pytorch</span></code> doesn’t provide a convenience api for freerun, here we implement a
simple version that all the prefixes will be recalculated at every step.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">metric</span> <span class="o">=</span> <span class="n">dataloader</span><span class="o">.</span><span class="n">get_inference_metric</span><span class="p">(</span><span class="n">gen_key</span><span class="o">=</span><span class="s2">&quot;gen&quot;</span><span class="p">)</span>
<span class="n">generate_sample_num</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">max_sent_length</span> <span class="o">=</span> <span class="mi">20</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">generate_sample_num</span><span class="p">):</span>
    <span class="c1"># convert numpy to torch.LongTensor</span>
    <span class="n">data</span><span class="p">[</span><span class="s1">&#39;sent&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="n">dataloader</span><span class="o">.</span><span class="n">go_id</span><span class="p">]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)])</span>
    <span class="n">data</span><span class="p">[</span><span class="s1">&#39;sent_length&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)])</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_sent_length</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">net</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">generated_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;gen_log_prob&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">()[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;sent&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;sent&#39;</span><span class="p">],</span> <span class="n">generated_token</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">metric</span><span class="o">.</span><span class="n">forward</span><span class="p">({</span><span class="s2">&quot;gen&quot;</span><span class="p">:</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;sent&#39;</span><span class="p">][:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()})</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">metric</span><span class="o">.</span><span class="n">close</span><span class="p">(),</span> <span class="n">width</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
</pre></div>
</div>
<p>Out:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>100%|██████████| 1000/1000 [00:00&lt;00:00, 1104.71it/s]
100%|██████████| 1250/1250 [00:01&lt;00:00, 1092.16it/s]
{&#39;bw-bleu&#39;: 0.0552594607682451,
 &#39;fw-bleu&#39;: 0.26895525176213,
 &#39;fw-bw-bleu&#39;: 0.0916819725247384,
 &#39;fw-bw-bleu hashvalue&#39;: &#39;b8b072913c122176b5a4bd3954eb1f48c921bb6c9e90b0e4547f2ad98cee56a5&#39;,
 &#39;gen&#39;: [[&#39;A&#39;, &#39;herd&#39;, &#39;of&#39;, &#39;items&#39;, &#39;with&#39;, &#39;different&#39;, &#39;toppings&#39;, &#39;on&#39;, &#39;a&#39;, &#39;snow&#39;, &#39;competition&#39;, &#39;.&#39;],
     [&#39;A&#39;, &#39;woman&#39;, &#39;oven&#39;, &#39;sits&#39;, &#39;decorated&#39;, &#39;and&#39;, &#39;forks&#39;, &#39;and&#39;, &#39;flowers&#39;, &#39;.&#39;],
     [&#39;A&#39;, &#39;couple&#39;, &#39;of&#39;, &#39;&lt;unk&gt;&#39;, &#39;made&#39;, &#39;with&#39;, &#39;into&#39;, &#39;a&#39;, &#39;container&#39;, &#39;of&#39;, &#39;people&#39;, &#39;.&#39;],
     [&#39;A&#39;, &#39;person&#39;, &#39;sitting&#39;, &#39;at&#39;, &#39;the&#39;, &#39;snow&#39;, &#39;flower&#39;, &#39;by&#39;, &#39;a&#39;, &#39;drink&#39;, &#39;shows&#39;, &#39;his&#39;, &#39;giraffe&#39;, &#39;.&#39;],
     [&#39;A&#39;, &#39;girl&#39;, &#39;standing&#39;, &#39;on&#39;, &#39;the&#39;, &#39;wall&#39;, &#39;outfit&#39;, &#39;in&#39;, &#39;the&#39;, &#39;pedestrian&#39;, &#39;roses&#39;, &#39;.&#39;],
     [&#39;A&#39;, &#39;young&#39;, &#39;girl&#39;, &#39;is&#39;, &#39;standing&#39;, &#39;by&#39;, &#39;businesses&#39;, &#39;raised&#39;, &#39;.&#39;],
     [&#39;A&#39;, &#39;small&#39;, &#39;baseball&#39;, &#39;pitcher&#39;, &#39;down&#39;, &#39;a&#39;, &#39;tennis&#39;, &#39;ball&#39;, &#39;.&#39;],
     [&#39;A&#39;, &#39;boat&#39;, &#39;and&#39;, &#39;bananas&#39;, &#39;train&#39;, &#39;in&#39;, &#39;a&#39;, &#39;field&#39;, &#39;.&#39;],
     [&#39;A&#39;, &#39;white&#39;, &#39;double&#39;, &#39;decker&#39;, &#39;dock&#39;, &#39;sitting&#39;, &#39;inside&#39;, &#39;of&#39;, &#39;an&#39;, &#39;airplane&#39;, &#39;.&#39;],
     [&#39;A&#39;, &#39;boy&#39;, &#39;being&#39;, &#39;transit&#39;, &#39;fire&#39;, &#39;hydrant&#39;, &#39;in&#39;, &#39;a&#39;, &#39;room&#39;, &#39;.&#39;],
     [&#39;A&#39;, &#39;white&#39;, &#39;sink&#39;, &#39;&lt;unk&gt;&#39;, &#39;a&#39;, &#39;vase&#39;, &#39;with&#39;, &#39;two&#39;, &#39;drinks&#39;, &#39;.&#39;],
     [&#39;A&#39;, &#39;very&#39;, &#39;cute&#39;, &#39;black&#39;, &#39;clock&#39;, &#39;sitting&#39;, &#39;on&#39;, &#39;ski&#39;, &#39;&lt;unk&gt;&#39;, &#39;near&#39;, &#39;a&#39;, &#39;hallway&#39;, &#39;.&#39;],
     [&#39;A&#39;, &#39;large&#39;, &#39;plate&#39;, &#39;sliced&#39;, &#39;with&#39;, &#39;tomatoes&#39;, &#39;in&#39;, &#39;the&#39;, &#39;water&#39;, &#39;.&#39;],
     [&#39;A&#39;, &#39;plane&#39;, &#39;with&#39;, &#39;a&#39;, &#39;laptop&#39;, &#39;and&#39;, &#39;set&#39;, &#39;of&#39;, &#39;furniture&#39;, &#39;.&#39;],
     [&#39;A&#39;, &#39;person&#39;, &#39;sitting&#39;, &#39;on&#39;, &#39;a&#39;, &#39;skateboard&#39;, &#39;walk&#39;, &#39;a&#39;, &#39;dirt&#39;, &#39;area&#39;, &#39;near&#39;, &#39;the&#39;, &#39;.&#39;],
     [&#39;A&#39;, &#39;young&#39;, &#39;boy&#39;, &#39;laying&#39;, &#39;around&#39;, &#39;with&#39;, &#39;a&#39;, &#39;red&#39;, &#39;table&#39;, &#39;.&#39;]],
&#39;self-bleu&#39;: 0.05696094523203348,
&#39;self-bleu hashvalue&#39;: &#39;90865484e69f47cf7aea7f89b1b1b563972ed140e8f0e6e8ec8064b7155c534c&#39;}
</pre></div>
</div>
</div>
<div class="section" id="hash-value">
<h3>Hash value<a class="headerlink" href="#hash-value" title="Permalink to this headline">¶</a></h3>
<p>Hash value is for checking whether you use the test set correctly.
We can refer to the <a class="reference external" href="http://coai.cs.tsinghua.edu.cn/dashboard/">dashboard</a> for the state of art on this dataset,
and we find our hashvalue is correct.</p>
<p>However, if teacher forcing is tested as following codes, we will
see a different hash value, which means the implementation is not correct.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">metric</span> <span class="o">=</span> <span class="n">dataloader</span><span class="o">.</span><span class="n">get_teacher_forcing_metric</span><span class="p">(</span><span class="n">gen_log_prob_key</span><span class="o">=</span><span class="s2">&quot;gen_log_prob&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="o">.</span><span class="n">get_batches</span><span class="p">(</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)):</span>
    <span class="c1"># convert numpy to torch.LongTensor</span>
    <span class="n">data</span><span class="p">[</span><span class="s1">&#39;sent&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;sent&#39;</span><span class="p">])</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">net</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">assert</span> <span class="s2">&quot;gen_log_prob&quot;</span> <span class="ow">in</span> <span class="n">data</span>
    <span class="n">metric</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">15</span><span class="p">:</span> <span class="c1">#ignore the following batches leading to an incorrect implementation</span>
        <span class="k">break</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">metric</span><span class="o">.</span><span class="n">close</span><span class="p">(),</span> <span class="n">width</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
</pre></div>
</div>
<p>Out:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>test set restart, 78 batches and 2 left
{&#39;perplexity&#39;: 31.935582929323076, &#39;perplexity hashvalue&#39;: &#39;d38265b09387b07be8461f54a7879250b196b0f5bbd3669dc5c6cd17958d81f8&#39;}
</pre></div>
</div>
</div>
</div>
<div class="section" id="additional-word-vector">
<h2>Additional: Word Vector<a class="headerlink" href="#additional-word-vector" title="Permalink to this headline">¶</a></h2>
<p>It is a common technique to use pre-trained word vector when
processing natural languages. <code class="docutils literal notranslate"><span class="pre">cotk</span></code> also provides a module <a class="reference internal" href="../wordvector.html#module-cotk.wordvector" title="cotk.wordvector"><code class="xref py py-mod docutils literal notranslate"><span class="pre">wordvector</span></code></a>
that help you downloading and get word vectors.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">cotk.wordvector</span> <span class="kn">import</span> <span class="n">Glove</span>
<span class="n">wordvec</span> <span class="o">=</span> <span class="n">Glove</span><span class="p">(</span><span class="s2">&quot;resources://Glove50d_small&quot;</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">embedding_layer</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">wordvec</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">embedding_size</span><span class="p">,</span> <span class="n">dataloader</span><span class="o">.</span><span class="n">frequent_vocab_list</span><span class="p">)))</span>
</pre></div>
</div>
<p>We can add these lines at the end of <code class="docutils literal notranslate"><span class="pre">LanguageModel.__init__</span></code>.</p>
<p><strong>Source code</strong></p>
<p>You can find the results and codes with pretrained word vector at
<a class="reference external" href="https://github.com/thu-coai/cotk/blob/master/docs/source/notes/tutorial_core_2.ipynb">here</a> for ipynb files
or run <a class="reference external" href="http://colab.research.google.com/github/thu-coai/cotk/blob/master/docs/source/notes/tutorial_core_2.ipynb">the code</a>
on google colab.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="cli_usage.html" class="btn btn-neutral float-right" title="CLI Usage" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="quickstart.html" class="btn btn-neutral float-left" title="Quick Start" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, thu-coai

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>